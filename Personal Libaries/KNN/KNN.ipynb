{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the K-nearest neighbors classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-nearest neighbors classification algorithm is a fairly straightforward algorithm. One takes the training set and memorizes it, including the class each point belongs to. Then, in order to predict the class of a new datapoint, one takes the K-nearest neighbors based on a distance metric, e.g. Euclidean distance.  Once this is done, the number of appearances of each class will be counted and the datapoint will be assigned to the class with the highest amount of appearances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the K-nearest neighbor algorithm, fitting is trivial as training implies telling the algorithm what the X and y sets are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X,y):\n",
    "    global X_f, y_f\n",
    "    X_f = X\n",
    "    y_f = y\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct the function that lies at the core of the algorithm. This function will take the datapoints to be classified and, based on the KNN algorithm, will assign a class to each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, neighbors):\n",
    "    global cl_p\n",
    "    cl_p =  np.array([])\n",
    "    for i in range(0,X.shape[0]):\n",
    "        #construct the vector consisting of the distance between each point of the training set\n",
    "        #with regard to the test point\n",
    "        a = X_f-X[i]\n",
    "        length_vector = np.linalg.norm(a, axis =1 )\n",
    "        #Take the vector and find the index of the k nearest neighbors in the training set\n",
    "        partition = np.argpartition(length_vector, neighbors)\n",
    "        y_nn = y_f[partition[:neighbors]]\n",
    "        cl_p = np.append(cl_p,  np.argmax(np.bincount(y_nn)))\n",
    "    return cl_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the algorithm and comparing to the sklearn version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import and use a simple yes or no dataset to test our algorithm. We will also compare  to the KNN module of sklearn.scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Social_Network_Ads.csv')\n",
    "y=data.Purchased.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use a Label Encoder as we have one categorical data category. This category tells us the Gender of the person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE=LabelEncoder()\n",
    "\n",
    "data['Gender'] = LE.fit_transform(data['Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset for the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:-1].values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit and proceed to predict the classes of our validation set. We will use the mean absolure error as a metric for the loss on this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr= predict(X_valid, 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid, pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the KNeighborsClassifier from sklearn and proceed to measure its error on the same dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN= KNeighborsClassifier(n_neighbors = 10)\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid, KNN.predict(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our algorithm performs equally well on this dataset! In the future it would be worth to check its accuracy on a dataset containing more than two datasets. This will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
